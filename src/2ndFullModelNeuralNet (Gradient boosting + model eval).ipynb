{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.0' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/alexa/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "First Full model for neural network.\n",
    "Need to do more preprocessing, maybe use ensemble techs?\n",
    "  Average MSE: 1762373241.38\n",
    "  Average RMSE: 40877.9508149\n",
    "  Average Sale Price: $180615.06\n",
    "  Average RMSE: $40877.95\n",
    "  RMSE as Percentage of Average Sale Price: 22.63%\n",
    "  Baseline RMSE: $79258.23\n",
    "  Model RMSE is better than baseline.\n",
    "  Logarithmic RMSE: 3.0168102385336213\n",
    "\n",
    "2nd: enoded additional categorical \n",
    "  MSE scores for each fold: [  1.05978198e+09   1.48816898e+09   1.65048210e+09   3.81049748e+09\n",
    "    1.25836784e+09]\n",
    "  RMSE scores for each fold: [ 32554.29274558  38576.79329149  40626.12589008  61729.22710779\n",
    "    35473.48081063]\n",
    "  Average MSE: 1853459676.36\n",
    "  Average RMSE: 41791.9839691\n",
    "  Average Sale Price: $180615.06\n",
    "  Average RMSE: $41791.98\n",
    "  RMSE as Percentage of Average Sale Price: 23.14%\n",
    "  Baseline RMSE: $79258.23\n",
    "  Model RMSE is better than baseline.\n",
    "  Logarithmic RMSE: 2.4033767712078378\n",
    "\n",
    "  \n",
    "3rd: added 0s for missing values instead of dropping and used MinMaxScaler()\n",
    "Logarithmic RMSE: 0.5253631751233521\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################Evaluating Gradient Boosting Model#########################\n",
      "MSE scores for each fold: [  6.97187557e+08   4.04300432e+08   1.93833611e+09   7.01262809e+08\n",
      "   4.55017473e+08]\n",
      "RMSE scores for each fold: [ 26404.30944522  20107.22336943  44026.53867699  26481.36720439\n",
      "  21331.13857671]\n",
      "Average MSE: 839220875.755\n",
      "Average RMSE: 27670.1154545\n",
      "Average Sale Price: $180921.20\n",
      "Average RMSE: $27670.12\n",
      "RMSE as Percentage of Average Sale Price: 15.29%\n",
      "Baseline RMSE: $79415.29\n",
      "Model RMSE is better than baseline.\n",
      "Logarithmic RMSE: 0.3818543996864455\n",
      "#####################Evaluating Neural Network Model#########################\n",
      "MSE scores for each fold: [  1.03509743e+09   1.11971635e+09   3.77621560e+09   9.78745738e+08\n",
      "   6.16715773e+08]\n",
      "RMSE scores for each fold: [ 32172.9301224   33462.16289029  61450.92029345  31284.91229929\n",
      "  24833.76276855]\n",
      "Average MSE: 1505298178.74\n",
      "Average RMSE: 36640.9376748\n",
      "Average Sale Price: $180921.20\n",
      "Average RMSE: $36640.94\n",
      "RMSE as Percentage of Average Sale Price: 20.25%\n",
      "Baseline RMSE: $79415.29\n",
      "Model RMSE is better than baseline.\n",
      "Logarithmic RMSE: 0.5253631751233521\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "def load_and_initial_clean(filepath):\n",
    "    \"\"\" Load the dataset and drop irrelevant columns. \"\"\"\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data\n",
    "\n",
    "def fill_missing_values(data):\n",
    "    \"\"\" Fill missing numerical values and drop rows for specific cases. \"\"\"\n",
    "    data['LotArea'].fillna(data['LotArea'].median(), inplace=True)\n",
    "    \n",
    "    if data['LotFrontage'].isnull().any():\n",
    "        predict_missing_values(data, 'LotFrontage', 'LotArea')\n",
    "    \n",
    "    data['GarageYrBlt'].fillna(0, inplace=True)\n",
    "    data['HasGarage'] = data['GarageYrBlt'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    columns_to_fill = [\n",
    "        'TotalBsmtSF', 'BsmtFullBath', 'GarageCars', 'GarageArea',\n",
    "        'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'BsmtHalfBath', 'MasVnrArea'\n",
    "    ]\n",
    "    data[columns_to_fill] = data[columns_to_fill].fillna(0)\n",
    "    return data\n",
    "\n",
    "def predict_missing_values(data, target_column, predictor_column):\n",
    "    \"\"\" Predict missing values in a target column using a predictor column. \"\"\"\n",
    "    non_na_data = data.dropna(subset=[target_column])\n",
    "    model = LinearRegression()\n",
    "    model.fit(non_na_data[[predictor_column]], non_na_data[target_column])\n",
    "    missing_indices = data[target_column].isnull()\n",
    "    data.loc[missing_indices, target_column] = model.predict(data.loc[missing_indices, [predictor_column]])\n",
    "\n",
    "def get_season(month):\n",
    "    \"\"\" Convert month number to season name. \"\"\"\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "\n",
    "def engineer_features(data):\n",
    "    \"\"\" Add new features and handle categorical variables. \"\"\"\n",
    "    data['TotalSF'] = data['1stFlrSF'] + data['2ndFlrSF'] + data['TotalBsmtSF']\n",
    "    data['HouseAge'] = data['YrSold'] - data['YearBuilt']\n",
    "    data['RemodelAge'] = data['YrSold'] - data['YearRemodAdd']\n",
    "    data['HasBasement'] = data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    data['TotalBath'] = data['FullBath'] + 0.5 * data['HalfBath'] + data['BsmtFullBath'] + 0.5 * data['BsmtHalfBath']\n",
    "    data['OverallScore'] = data['OverallQual'] + data['OverallCond']\n",
    "    data['LotFrontageRatio'] = data['LotFrontage'] / data['LotArea']\n",
    "    data['SaleSeason'] = data['MoSold'].apply(get_season)\n",
    "    \n",
    "    categorical_cols = [\n",
    "        'MSSubClass', 'Alley', 'MSZoning', 'Street', 'LotShape',\n",
    "        'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
    "        'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
    "        'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    "        'Exterior2nd', 'Foundation', 'Heating', 'CentralAir',\n",
    "        'Functional', 'GarageType', 'GarageFinish', 'PavedDrive',\n",
    "        'MiscFeature', 'SaleType', 'SaleCondition', 'SaleSeason',\n",
    "        'MasVnrType', 'Electrical', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n",
    "        'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC',\n",
    "        'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC',\n",
    "        'Fence'\n",
    "    ]\n",
    "    data = pd.get_dummies(data, columns=categorical_cols, dummy_na=True)\n",
    "    return data\n",
    "\n",
    "def add_missing_features_test(data):\n",
    "    \"\"\" Add missing features to the DataFrame. \"\"\"\n",
    "    missing_features = [\n",
    "        'PoolQC_Fa', 'Condition2_RRAe', 'Heating_OthW', 'RoofMatl_Metal',\n",
    "        'Condition2_RRAn', 'RoofMatl_Roll', 'Electrical_Mix', 'HouseStyle_2.5Fin',\n",
    "        'Heating_Floor', 'RoofMatl_Membran', 'Condition2_RRNn', 'MiscFeature_TenC',\n",
    "        'Exterior2nd_Other', 'Exterior1st_Stone', 'Utilities_NoSeWa', 'RoofMatl_ClyTile',\n",
    "        'GarageQual_Ex', 'Exterior1st_ImStucc'\n",
    "    ]\n",
    "\n",
    "    for feature in missing_features:\n",
    "        data[feature] = 0\n",
    "\n",
    "def add_missing_features_train(data):\n",
    "    #missing NA features. i.e one hot encoded features that have no NA, are not here\n",
    "    missing_features = [\n",
    "    'MSSubClass_150.0']\n",
    "\n",
    "    # Add each missing feature to the test set with all values set to 0\n",
    "    for feature in missing_features:\n",
    "        data[feature] = 0\n",
    "\n",
    "def save_preprocessed_data(data, output_file_path):\n",
    "    \"\"\" Save the preprocessed data to a CSV file. \"\"\"\n",
    "    data.to_csv(output_file_path, index=False)\n",
    "\n",
    "def train_gradient_boosting(X, y):\n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = -cross_val_score(model, X, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    rmse_scores = np.sqrt(mse_scores)  # Convert MSE to RMSE\n",
    "\n",
    "    print(\"MSE scores for each fold:\", mse_scores)\n",
    "    print(\"RMSE scores for each fold:\", rmse_scores)\n",
    "    print(\"Average MSE:\", np.mean(mse_scores))\n",
    "    print(\"Average RMSE:\", np.mean(rmse_scores))\n",
    "\n",
    "    average_price = y.mean()\n",
    "    rmse_percentage = (rmse_scores.mean() / average_price) * 100\n",
    "    print(f\"Average Sale Price: ${average_price:.2f}\")\n",
    "    print(f\"Average RMSE: ${rmse_scores.mean():.2f}\")\n",
    "    print(f\"RMSE as Percentage of Average Sale Price: {rmse_percentage:.2f}%\")\n",
    "\n",
    "    baseline_rmse = np.sqrt(mean_squared_error(y, [y.mean()] * len(y)))\n",
    "    print(f\"Baseline RMSE: ${baseline_rmse:.2f}\")\n",
    "    if rmse_scores.mean() < baseline_rmse:\n",
    "        print(\"Model RMSE is better than baseline.\")\n",
    "    else:\n",
    "        print(\"Model RMSE is not better than baseline.\")\n",
    "\n",
    "    \n",
    "\n",
    "def get_logrmse(predictions_path, sample_path):\n",
    "    # Load the predictions and actual values\n",
    "    predictions_df = pd.read_csv(predictions_path)\n",
    "    actual_df = pd.read_csv(sample_path)\n",
    "\n",
    "    # Sort both DataFrames by 'Id' to ensure alignment\n",
    "    predictions_df.sort_values('Id', inplace=True)\n",
    "    actual_df.sort_values('Id', inplace=True)\n",
    "\n",
    "    # Find mismatched IDs\n",
    "    predictions_ids = set(predictions_df['Id'])\n",
    "    actual_ids = set(actual_df['Id'])\n",
    "    mismatched_ids = actual_ids - predictions_ids\n",
    "\n",
    "    # Warn if there are mismatches and adjust the actual values DataFrame\n",
    "    if mismatched_ids:\n",
    "        warnings.warn(f\"Mismatched IDs found: {mismatched_ids}. Please correct.\")\n",
    "        #actual_df = actual_df[actual_df['Id'].isin(predictions_ids)]\n",
    "    else:\n",
    "        # Ensure the adjusted DataFrames are aligned correctly\n",
    "        actual_df.sort_values('Id', inplace=True)  # Re-sort to ensure order after adjustments\n",
    "\n",
    "        # Calculate the logarithm of predictions and actual values to prevent scale bias\n",
    "        log_predictions = np.log(predictions_df['SalePrice'] + 1)\n",
    "        log_actual = np.log(actual_df['SalePrice'] + 1)\n",
    "\n",
    "        # Calculate RMSE using the log-transformed values\n",
    "        mse = mean_squared_error(log_actual, log_predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        print(f'Logarithmic RMSE: {rmse}')\n",
    "\n",
    "def main():\n",
    "    file_path = 'train.csv'\n",
    "    output_file_path = 'train_with_features_Gus.csv'\n",
    "    \n",
    "    data = load_and_initial_clean(file_path)\n",
    "    data.drop('Id', axis=1, inplace=True)\n",
    "    data = fill_missing_values(data)\n",
    "    data = engineer_features(data)\n",
    "    add_missing_features_train(data)\n",
    "    save_preprocessed_data(data, output_file_path)\n",
    "\n",
    "    file_path_test = 'test.csv'\n",
    "    output_file_path_test = 'test_with_features_Gus.csv'\n",
    "    test_data = load_and_initial_clean(file_path_test)\n",
    "    test_data = fill_missing_values(test_data)\n",
    "    test_data = engineer_features(test_data)\n",
    "    add_missing_features_test(test_data)\n",
    "    save_preprocessed_data(test_data, output_file_path_test)\n",
    "    \n",
    "    X = data.drop('SalePrice', axis=1)\n",
    "    y = data['SalePrice']\n",
    "    \n",
    "    # Train and evaluate Gradient Boosting model\n",
    "    gb_model = train_gradient_boosting(X, y)\n",
    "    print(\"#####################Evaluating Gradient Boosting Model#########################\")\n",
    "    evaluate_model(gb_model, X, y)\n",
    "    # Predict on the test data\n",
    "    test_data = pd.read_csv(output_file_path_test)\n",
    "    X_test = test_data.drop('Id', axis=1)\n",
    "    gb_model.fit(X, y)\n",
    "    y_test_pred = gb_model.predict(X_test)\n",
    "\n",
    "    # Create a DataFrame for submission that includes the Id and the predicted prices\n",
    "    submission = pd.DataFrame({\n",
    "        'Id': test_data['Id'],\n",
    "        'SalePrice': y_test_pred\n",
    "    })\n",
    "    submission.to_csv('predictions_GB.csv', index=False)\n",
    "    get_logrmse('predictions_GB.csv', 'sample_submission.csv')\n",
    "    \n",
    "    # Save the submission file\n",
    "\n",
    "    #print(\"#####################Logarithmic RMSE For Gradient Boosting Model#########################\")\n",
    "    #get_logrmse('predictions.csv', 'sample_submission.csv')\n",
    "    \n",
    "\n",
    "    print(\"#####################Evaluating Neural Network Model#########################\")\n",
    "    # Fit and evaluate the Neural Network model for comparison\n",
    "    pipeline = make_pipeline(\n",
    "        MinMaxScaler(),\n",
    "        MLPRegressor(\n",
    "            hidden_layer_sizes=(128, 64, 50),\n",
    "            activation='relu',\n",
    "            solver='adam',\n",
    "            alpha=0.0001,\n",
    "            learning_rate_init=0.001,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    evaluate_model(pipeline, X, y)\n",
    "    \n",
    "    pipeline.fit(X, y)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Create a DataFrame for submission that includes the Id and the predicted prices\n",
    "    submission = pd.DataFrame({\n",
    "        'Id': test_data['Id'],\n",
    "        'SalePrice': y_test_pred\n",
    "    })\n",
    "    submission.to_csv('predictions_NN.csv', index=False)\n",
    "    get_logrmse('predictions_NN.csv', 'sample_submission.csv')\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
