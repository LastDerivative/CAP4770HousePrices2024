{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def load_and_initial_clean(filepath):\n",
    "    \"\"\" Load the dataset and drop irrelevant columns. \"\"\"\n",
    "    data = pd.read_csv(filepath)\n",
    "    data.drop('Id', axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def handle_missing_values(data):\n",
    "    \"\"\" Fill and predict missing numerical values and drop rows for specific cases. \"\"\"\n",
    "    # Handle 'LotArea' missing values\n",
    "    data['LotArea'].fillna(data['LotArea'].median(), inplace=True)\n",
    "    \n",
    "    # Predict missing 'LotFrontage' using Linear Regression\n",
    "    if data['LotFrontage'].isnull().any():\n",
    "        non_na_data = data.dropna(subset=['LotFrontage'])\n",
    "        model = LinearRegression()\n",
    "        model.fit(non_na_data[['LotArea']], non_na_data['LotFrontage'])\n",
    "        missing_indices = data['LotFrontage'].isnull()\n",
    "        data.loc[missing_indices, 'LotFrontage'] = model.predict(data.loc[missing_indices, ['LotArea']])\n",
    "    \n",
    "    # Drop rows where 'MasVnrArea' is NA\n",
    "    # data.dropna(subset=['MasVnrArea'], inplace=True)\n",
    "    data['MasVnrArea'].fillna(0, inplace=True) #using 0 instead\n",
    "\n",
    "    # Fill 'GarageYrBlt' NAs indicating no garage\n",
    "    data['GarageYrBlt'].fillna(0, inplace=True)\n",
    "    data['HasGarage'] = data['GarageYrBlt'].apply(lambda x: 1 if x > 0 else 0)\n",
    "  \n",
    "\n",
    "def get_season(month):\n",
    "    \"\"\" Convert month number to season name. \"\"\"\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "\n",
    "def feature_engineering(data):\n",
    "    \"\"\"Add new features and handle categorical variables.\"\"\"\n",
    "    # Numerical features\n",
    "    data['TotalSF'] = data['1stFlrSF'] + data['2ndFlrSF'] + data['TotalBsmtSF']\n",
    "    data['HouseAge'] = data['YrSold'] - data['YearBuilt']\n",
    "    data['RemodelAge'] = data['YrSold'] - data['YearRemodAdd']\n",
    "    data['HasBasement'] = data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    data['TotalBath'] = data['FullBath'] + 0.5 * data['HalfBath'] + data['BsmtFullBath'] + 0.5 * data['BsmtHalfBath']\n",
    "    data['OverallScore'] = data['OverallQual'] + data['OverallCond']\n",
    "    data['LotFrontageRatio'] = data['LotFrontage'] / data['LotArea']\n",
    "    data['SaleSeason'] = data['MoSold'].apply(get_season)\n",
    "    # Price per SF: no column in test\n",
    "    # data['PricePerSF'] = data['SalePrice'] / data['TotalSF']\n",
    "\n",
    "\n",
    "    # Categorical features - One Hot Encoding\n",
    "    categorical_cols = [\n",
    "        'MSSubClass', 'Alley', 'MSZoning', 'Street', 'LotShape',\n",
    "        'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
    "        'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
    "        'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    "        'Exterior2nd', 'Foundation', 'Heating', 'CentralAir',\n",
    "        'Functional', 'GarageType', 'GarageFinish', 'PavedDrive',\n",
    "        'MiscFeature', 'SaleType', 'SaleCondition', 'SaleSeason',\n",
    "        'MasVnrType', 'Electrical', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n",
    "        'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC',\n",
    "        'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC',\n",
    "        'Fence'\n",
    "        ]\n",
    "    data = pd.get_dummies(data, columns=categorical_cols, dummy_na=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def missing(data):\n",
    "    #missing NA features. i.e one hot encoded features that have no NA, are not here\n",
    "    missing_features = [\n",
    "    'MSSubClass_150.0']\n",
    "\n",
    "    # Add each missing feature to the test set with all values set to 0\n",
    "    for feature in missing_features:\n",
    "        data[feature] = 0\n",
    "\n",
    "\n",
    "def save_preprocessed_data(data, output_file_path):\n",
    "    \"\"\" Save the preprocessed data to a CSV file. \"\"\"\n",
    "    data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Main function to orchestrate the preprocessing\n",
    "def main():\n",
    "    file_path = 'train.csv'\n",
    "    output_file_path = 'train_with_features_Gus.csv'\n",
    "    \n",
    "    data = load_and_initial_clean(file_path)\n",
    "    handle_missing_values(data)\n",
    "    data = feature_engineering(data)\n",
    "    missing(data)\n",
    "    save_preprocessed_data(data, output_file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def load_and_initial_clean(filepath):\n",
    "    \"\"\" Load the dataset and drop irrelevant columns. \"\"\"\n",
    "    data = pd.read_csv(filepath)\n",
    "    #data.drop('Id', axis=1, inplace=True) #handled in modeling\n",
    "    return data\n",
    "\n",
    "def handle_missing_values(data):\n",
    "    \"\"\" Fill and predict missing numerical values and drop rows for specific cases. \"\"\"\n",
    "    # Handle 'LotArea' missing values\n",
    "    data['LotArea'].fillna(data['LotArea'].median(), inplace=True)\n",
    "    \n",
    "    # Predict missing 'LotFrontage' using Linear Regression\n",
    "    if data['LotFrontage'].isnull().any():\n",
    "        non_na_data = data.dropna(subset=['LotFrontage'])\n",
    "        model = LinearRegression()\n",
    "        model.fit(non_na_data[['LotArea']], non_na_data['LotFrontage'])\n",
    "        missing_indices = data['LotFrontage'].isnull()\n",
    "        data.loc[missing_indices, 'LotFrontage'] = model.predict(data.loc[missing_indices, ['LotArea']])\n",
    "    \n",
    "    # Drop rows where 'MasVnrArea' is NA\n",
    "    # data.dropna(subset=['MasVnrArea'], inplace=True) #setting to 0 to test\n",
    "    \n",
    "    # Fill 'GarageYrBlt' NAs indicating no garage\n",
    "    data['GarageYrBlt'].fillna(0, inplace=True)\n",
    "    data['HasGarage'] = data['GarageYrBlt'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    ##########################################################################\n",
    "    # Alternatively, you can handle multiple columns at once\n",
    "    columns_to_fill = ['TotalBsmtSF', 'BsmtFullBath', 'GarageCars', 'GarageArea',\n",
    "                       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'BsmtHalfBath', 'MasVnrArea']\n",
    "    data[columns_to_fill] = data[columns_to_fill].fillna(0)\n",
    "\n",
    "\n",
    "def get_season(month):\n",
    "    \"\"\" Convert month number to season name. \"\"\"\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "\n",
    "def feature_engineering(data):\n",
    "    \"\"\"Add new features and handle categorical variables.\"\"\"\n",
    "    # Numerical features\n",
    "    data['TotalSF'] = data['1stFlrSF'] + data['2ndFlrSF'] + data['TotalBsmtSF']\n",
    "    data['HouseAge'] = data['YrSold'] - data['YearBuilt']\n",
    "    data['RemodelAge'] = data['YrSold'] - data['YearRemodAdd']\n",
    "    data['HasBasement'] = data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    data['TotalBath'] = data['FullBath'] + 0.5 * data['HalfBath'] + data['BsmtFullBath'] + 0.5 * data['BsmtHalfBath']\n",
    "    data['OverallScore'] = data['OverallQual'] + data['OverallCond']\n",
    "    data['LotFrontageRatio'] = data['LotFrontage'] / data['LotArea']\n",
    "    data['SaleSeason'] = data['MoSold'].apply(get_season)\n",
    "\n",
    "    # Categorical features - One Hot Encoding\n",
    "    categorical_cols = [\n",
    "        #'MSSubClass', \n",
    "        'MSSubClass', 'Alley', 'MSZoning', 'Street', 'LotShape',\n",
    "        'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
    "        'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
    "        'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    "        'Exterior2nd', 'Foundation', 'Heating', 'CentralAir',\n",
    "        'Functional', 'GarageType', 'GarageFinish', 'PavedDrive',\n",
    "        'MiscFeature', 'SaleType', 'SaleCondition', 'SaleSeason',\n",
    "        'MasVnrType', 'Electrical', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n",
    "        'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC',\n",
    "        'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC',\n",
    "        'Fence'\n",
    "        ]\n",
    "    data = pd.get_dummies(data, columns=categorical_cols, dummy_na=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def missing(data):\n",
    "    #missing NA features. i.e one hot encoded features that have no NA, are not here\n",
    "    missing_features = [\n",
    "    'PoolQC_Fa', 'Condition2_RRAe', 'Heating_OthW', 'RoofMatl_Metal', \n",
    "    'Condition2_RRAn', 'RoofMatl_Roll', 'Electrical_Mix', 'HouseStyle_2.5Fin', \n",
    "    'Heating_Floor', 'RoofMatl_Membran', 'Condition2_RRNn', 'MiscFeature_TenC', \n",
    "    'Exterior2nd_Other', 'Exterior1st_Stone', 'Utilities_NoSeWa', 'RoofMatl_ClyTile', \n",
    "    'GarageQual_Ex', 'Exterior1st_ImStucc']\n",
    "\n",
    "    # Add each missing feature to the test set with all values set to 0\n",
    "    for feature in missing_features:\n",
    "        data[feature] = 0\n",
    "\n",
    "\n",
    "def save_preprocessed_data(data, output_file_path):\n",
    "    \"\"\" Save the preprocessed data to a CSV file. \"\"\"\n",
    "    data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Main function to orchestrate the preprocessing\n",
    "def main():\n",
    "    file_path = 'test.csv'\n",
    "    output_file_path = 'test_with_features_Gus.csv'\n",
    "    \n",
    "    data = load_and_initial_clean(file_path)\n",
    "    handle_missing_values(data)\n",
    "    data = feature_engineering(data)\n",
    "    missing(data)\n",
    "    save_preprocessed_data(data, output_file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE scores for each fold: [  1.03509743e+09   1.11971635e+09   3.77621560e+09   9.78745738e+08\n",
      "   6.16715773e+08]\n",
      "RMSE scores for each fold: [ 32172.9301224   33462.16289029  61450.92029345  31284.91229929\n",
      "  24833.76276855]\n",
      "Average MSE: 1505298178.74\n",
      "Average RMSE: 36640.9376748\n",
      "Average Sale Price: $180921.20\n",
      "Average RMSE: $36640.94\n",
      "RMSE as Percentage of Average Sale Price: 20.25%\n",
      "Baseline RMSE: $79415.29\n",
      "Model RMSE is better than baseline.\n",
      "Logarithmic RMSE: 0.5253631751233521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "# Load the data\n",
    "data = pd.read_csv('train_with_features_Gus.csv')\n",
    "X = data.drop('SalePrice', axis=1)\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Define a scaler and MLP regressor in a pipeline\n",
    "# This ensures that scaling is correctly reapplied for each cross-validation fold\n",
    "pipeline = make_pipeline(MinMaxScaler(), MLPRegressor(\n",
    "    hidden_layer_sizes=(128, 64, 50),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001,\n",
    "    batch_size='auto',\n",
    "    learning_rate='constant',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    "))\n",
    "\n",
    "# Set up K-Fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Calculate MSE across all folds\n",
    "mse_scores = -cross_val_score(pipeline, X, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(mse_scores)  # Convert MSE to RMSE\n",
    "\n",
    "print(\"MSE scores for each fold:\", mse_scores)\n",
    "print(\"RMSE scores for each fold:\", rmse_scores)\n",
    "print(\"Average MSE:\", np.mean(mse_scores))\n",
    "print(\"Average RMSE:\", np.mean(rmse_scores))\n",
    "\n",
    "\n",
    "average_price = y.mean()\n",
    "rmse_percentage = (rmse_scores.mean() / average_price) * 100\n",
    "print(f\"Average Sale Price: ${average_price:.2f}\")\n",
    "print(f\"Average RMSE: ${rmse_scores.mean():.2f}\")\n",
    "print(f\"RMSE as Percentage of Average Sale Price: {rmse_percentage:.2f}%\")\n",
    "\n",
    "# Compare with baseline RMSE\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y, [y.mean()] * len(y)))\n",
    "print(f\"Baseline RMSE: ${baseline_rmse:.2f}\")\n",
    "if rmse_scores.mean() < baseline_rmse:\n",
    "    print(\"Model RMSE is better than baseline.\")\n",
    "else:\n",
    "    print(\"Model RMSE is not better than baseline.\")\n",
    "\n",
    "#######################################################################################\n",
    "# Testing: Load the preprocessed test data\n",
    "test_data = pd.read_csv('test_with_features_Gus.csv')\n",
    "\n",
    "# Assuming the first column is 'Id' and the rest are features used for prediction\n",
    "X_test = test_data.drop('Id', axis=1)  # Drop 'Id' for prediction purposes\n",
    "\n",
    "# Fit the pipeline to the full training data\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Create a DataFrame for submission that includes the Id and the predicted prices\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_data['Id'],\n",
    "    'SalePrice': y_test_pred\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('predictions.csv', index=False)\n",
    "\n",
    "#######################################################################################\n",
    "# Load the predictions and actual values\n",
    "predictions_df = pd.read_csv('predictions.csv')\n",
    "actual_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# Sort both DataFrames by 'Id' to ensure alignment\n",
    "predictions_df.sort_values('Id', inplace=True)\n",
    "actual_df.sort_values('Id', inplace=True)\n",
    "\n",
    "# Find mismatched IDs\n",
    "predictions_ids = set(predictions_df['Id'])\n",
    "actual_ids = set(actual_df['Id'])\n",
    "mismatched_ids = actual_ids - predictions_ids\n",
    "\n",
    "# Warn if there are mismatches and adjust the actual values DataFrame\n",
    "if mismatched_ids:\n",
    "    warnings.warn(f\"Mismatched IDs found: {mismatched_ids}. These will be removed from the actuals.\")\n",
    "    actual_df = actual_df[actual_df['Id'].isin(predictions_ids)]\n",
    "\n",
    "# Ensure the adjusted DataFrames are aligned correctly\n",
    "actual_df.sort_values('Id', inplace=True)  # Re-sort to ensure order after adjustments\n",
    "\n",
    "\n",
    "# Calculate the logarithm of predictions and actual values to prevent scale bias\n",
    "log_predictions = np.log(predictions_df['SalePrice'] + 1)\n",
    "log_actual = np.log(actual_df['SalePrice'] + 1)\n",
    "\n",
    "# Calculate RMSE using the log-transformed values\n",
    "mse = mean_squared_error(log_actual, log_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'Logarithmic RMSE: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
